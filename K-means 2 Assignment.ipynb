{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ba1e5-9dfb-4555-b1b6-ed46e7b5c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?\n",
    "Ans..Hierarchical clustering is an unsupervised machine learning algorithm used for clustering and segmentation of data. The algorithm groups similar\n",
    "    data points into clusters using a hierarchical approach, either by dividing the data into smaller sub-clusters (divisive) or by merging smaller \n",
    "    clusters into larger ones (agglomerative). \n",
    "    \n",
    "    K-means clustering is a popular unsupervised machine learning algorithm used for clustering and segmentation of data. The algorithm partitions\n",
    "    a given dataset into K clusters, where each data point is assigned to the cluster with the nearest mean or centroid.\n",
    "     \n",
    "    DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a popular unsupervised machine learning algorithm used for clustering \n",
    "    and segmentation of data. The algorithm groups together data points that are closely packed together and marks data points that are in sparse\n",
    "    areas as noise or outliers.\n",
    "    \n",
    "    \n",
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief.\n",
    "Ans.-1.Agglomerative: Initially consider every data point as an individual Cluster and at every step, merge the nearest pairs of the cluster. (It is a \n",
    "    bottom-up method). At first, every dataset is considered an individual entity or cluster. At every iteration, the clusters merge with different \n",
    "    clusters until one cluster is formed. \n",
    "\n",
    "    The algorithm for Agglomerative Hierarchical Clustering is:\n",
    "        1.Calculate the similarity of one cluster with all the other clusters (calculate proximity matrix)\n",
    "        2.Consider every data point as an individual cluster\n",
    "        3.Merge the clusters which are highly similar or close to each other.\n",
    "        4.Recalculate the proximity matrix for each cluster\n",
    "        5.Repeat Steps 3 and 4 until only a single cluster remains.\n",
    "        \n",
    "     2.Divisive Hierarchical clustering is the opposite of Agglomerative Hierarchical clustering.\n",
    "    \n",
    "    \n",
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the common distance metrics used?\n",
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some common methods used for this purpose?\n",
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?\n",
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "distance metrics different for each type of data?\n",
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
