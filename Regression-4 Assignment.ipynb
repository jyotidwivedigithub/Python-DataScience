{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5aa081-96c1-4733-bd04-7bf2a53193f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "Ans.Lasso Regression: Lasso (Least Absolute Shrinkage and Selection Operator) regression is a linear regression technique that adds a penalty term \n",
    "   (L1 regularization) to the ordinary least squares (OLS) loss function. This penalty term penalizes the absolute magnitude of the coefficients, \n",
    "    encouraging sparsity and feature selection by forcing some coefficients to exactly zero.\n",
    "\n",
    "    Differences:\n",
    "        1.Lasso regression differs from ordinary least squares (OLS) regression by adding an L1 penalty term to the loss function.\n",
    "        2.Compared to Ridge regression, Lasso regression tends to produce sparse models by setting some coefficients to zero, effectively performing \n",
    "         feature selection.\n",
    "\n",
    "\n",
    "\n",
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "Ans.The main advantage of Lasso regression in feature selection is its ability to automatically select relevant features by shrinking irrelevant coefficients\n",
    "   to zero. Lasso regression encourages sparsity in the coefficient vector, effectively eliminating less important predictors from the model. This can \n",
    "    lead to simpler and more interpretable models, especially in high-dimensional datasets with many predictors.\n",
    "\n",
    "\n",
    "\n",
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "Ans.The main tuning parameter in Lasso regression is lambda (λ), also known as the regularization parameter. Lambda controls the strength of the penalty\n",
    "    term and affects the level of shrinkage applied to the coefficients. Larger values of lambda lead to stronger regularization, resulting in more \n",
    "    coefficients being shrunk towards zero. The choice of lambda is typically determined using techniques such as cross-validation, where different \n",
    "    values of lambda are tested, and the one that minimizes the validation error is selected.\n",
    "\n",
    "\n",
    "\n",
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "Ans.The main tuning parameter in Lasso regression is lambda (λ), also known as the regularization parameter. Lambda controls the strength of the penalty \n",
    "    term and affects the level of shrinkage applied to the coefficients. Larger values of lambda lead to stronger regularization, resulting in more \n",
    "    coefficients being shrunk towards zero. The choice of lambda is typically determined using techniques such as cross-validation, where different \n",
    "    values of lambda are tested, and the one that minimizes the validation error is selected.\n",
    "\n",
    "\n",
    "\n",
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "Ans.Lasso regression is inherently a linear regression technique and is most suitable for linear regression problems. However, it can be used for \n",
    "   non-linear regression problems by incorporating non-linear transformations of the original features (e.g., polynomial features) into the model. By\n",
    "    including non-linear terms in the feature space, Lasso regression can capture non-linear relationships between predictors and the target variable.\n",
    "\n",
    "    \n",
    "    \n",
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "Ans.The main difference between Ridge regression and Lasso regression lies in the type of penalty term used:\n",
    "    1.Ridge regression adds an L2 penalty term to the loss function, which penalizes the squared magnitude of the coefficients.\n",
    "    2.Lasso regression adds an L1 penalty term, which penalizes the absolute magnitude of the coefficients and encourages sparsity.\n",
    "    \n",
    "    \n",
    "    \n",
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "Ans.Lasso regression can handle multicollinearity to some extent by shrinking coefficients towards zero, effectively reducing the impact of correlated \n",
    "   predictors. However, if predictors are highly correlated, Lasso regression may arbitrarily select one predictor over the other, leading to instability\n",
    "   in coefficient estimates. In such cases, careful interpretation and validation of the model are necessary.\n",
    "\n",
    "\n",
    "\n",
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "Ans.The optimal value of the regularization parameter (lambda) in Lasso regression is typically chosen using techniques such as cross-validation or \n",
    "  grid search. Cross-validation involves splitting the data into training and validation sets, fitting the Lasso regression model with different values\n",
    "  of lambda on the training set, and selecting the lambda value that minimizes the validation error. Grid search involves testing a predefined range of\n",
    "  lambda values and selecting the one that yields the best model performance. The chosen lambda value should strike a balance between model complexity\n",
    "  and predictive accuracy, avoiding both underfitting and overfitting.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
