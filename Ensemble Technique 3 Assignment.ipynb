{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d20065-23b2-4f24-b7e5-2c305d60e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Random Forest Regressor?\n",
    "Ans. Random Forest Regressor is a machine learning algorithm that belongs to the ensemble learning family. It is based on the principle of constructing\n",
    "   multiple decision trees during training and outputting the mean prediction of the individual trees for regression tasks.\n",
    "\n",
    "    \n",
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
    "Ans. Random Forest Regressor reduces the risk of overfitting through two main mechanism...\n",
    "    1.Random Feature Selection: At each split of a decision tree, the algorithm considers only a random subset of the features rather than all \n",
    "      features. This randomness helps prevent individual trees from becoming too specialized to the training data.\n",
    "    2.Bagging (Bootstrap Aggregating): Random Forest builds multiple decision trees from different subsets of the training data, sampled with \n",
    "      replacement. This variation in training data helps to generalize better to unseen data.\n",
    "\n",
    "        \n",
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
    "Ans. In a Random Forest Regressor, predictions are aggregated by averaging the predictions of all the individual decision trees. Each decision tree \n",
    "   contributes to the final prediction, and the mean of these predictions is taken as the final output.\n",
    "\n",
    "    \n",
    "Q4. What are the hyperparameters of Random Forest Regressor?\n",
    "Ans. Some common hyperparameters of the Random Forest Regressor include:\n",
    "    1.Number of trees in the forest (n_estimators)\n",
    "    2.Maximum depth of each tree (max_depth)\n",
    "    3.Minimum number of samples required to split an internal node (min_samples_split)\n",
    "    4.Minimum number of samples required to be at a leaf node (min_samples_leaf)\n",
    "    5.Maximum number of features to consider for splitting a node (max_features)\n",
    "\n",
    "    \n",
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
    "Ans. Difference between Random Forest Regressor and Decision Tree Regressor are...\n",
    "    1.Random Forest Regressor builds multiple decision trees during training, whereas Decision Tree Regressor builds a single decision tree.\n",
    "    2.Random Forest Regressor reduces overfitting by aggregating predictions from multiple trees, whereas Decision Tree Regressor may suffer from \n",
    "      overfitting if not properly pruned.\n",
    "    3.Random Forest Regressor typically provides better generalization performance compared to Decision Tree Regressor.\n",
    "\n",
    "    \n",
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
    "Ans. Advantages and Disadvantages of Random Forest Regressor...\n",
    "\n",
    "    Advantages:\n",
    "        1.Handles high-dimensional data well.\n",
    "        2.Robust to overfitting due to ensemble learning.\n",
    "        3.Can handle both regression and classification tasks.\n",
    "        4.Provides feature importance estimation.\n",
    "\n",
    "    Disadvantages:\n",
    "        1.May be computationally expensive, especially with large datasets and many trees.\n",
    "        2.May be more challenging to interpret compared to individual decision trees.\n",
    "        \n",
    "        \n",
    "Q7. What is the output of Random Forest Regressor?\n",
    "Ans. The output of a Random Forest Regressor is a continuous numerical value, which represents the predicted target variable for the input data.\n",
    "\n",
    "\n",
    "Q8. Can Random Forest Regressor be used for classification tasks?\n",
    "Ans. Random Forest can be used for classification tasks. The algorithm is quite flexible and can handle both regression and classification tasks \n",
    "    effectively. In classification tasks, it predicts the class label based on the majority vote of the individual trees in the forest.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
