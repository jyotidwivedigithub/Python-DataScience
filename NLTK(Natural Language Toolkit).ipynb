{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63694a10-b50f-4c8a-8e27-aeb51b9b8ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e7920f0-a697-435d-9e36-2359eed6a408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ce8f46d-374e-4ccf-858a-9b15c486e5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  /opt/conda/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  /opt/conda/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  /opt/conda/bin/python -m pip install [options] [-e] <vcs project url> ...\n",
      "  /opt/conda/bin/python -m pip install [options] [-e] <local project path> ...\n",
      "  /opt/conda/bin/python -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: --user-u-nltk\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user-u-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c44fde7a-e079-4d6d-a2ee-b5b3d807d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"NLTK is a powerful tool for NLP. it can tokenize sentences and word. It include various NLP libraries for text analysis. \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80eb587-9c35-4f94-83de-f1359d085ecf",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4663bf7a-af6e-4952-a8bc-bf2205ed1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "250b5e28-6efa-4027-9c13-990dd69198d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words: ['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'NLP', '.', 'it', 'can', 'tokenize', 'sentences', 'and', 'word', '.', 'It', 'include', 'various', 'NLP', 'libraries', 'for', 'text', 'analysis', '.']\n",
      "\n",
      "Tokenized sentences: ['NLTK is a powerful tool for NLP.', 'it can tokenize sentences and word.', 'It include various NLP libraries for text analysis.']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "words = word_tokenize(text)\n",
    "print(\"Tokenized words:\", words)\n",
    "print()\n",
    "print(\"Tokenized sentences:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51a2b1-e127-404b-9fc7-923b9d35c951",
   "metadata": {},
   "source": [
    "# Part-of-Speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca2b366b-e178-48d1-87d9-694187a81a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('powerful', 'JJ'), ('tool', 'NN'), ('for', 'IN'), ('NLP', 'NNP'), ('.', '.'), ('it', 'PRP'), ('can', 'MD'), ('tokenize', 'VB'), ('sentences', 'NNS'), ('and', 'CC'), ('word', 'NN'), ('.', '.'), ('It', 'PRP'), ('include', 'VBP'), ('various', 'JJ'), ('NLP', 'NNP'), ('libraries', 'NNS'), ('for', 'IN'), ('text', 'JJ'), ('analysis', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "pos_tags = pos_tag(words)\n",
    "print(\"POS Tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89006c-1f34-4eba-bb2a-264d2aa893ed",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22265d2a-ad45-4690-a78c-c961ab249427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "282fc4dd-c8ee-49ba-ba2f-aee60f3595ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['nltk', 'is', 'a', 'power', 'tool', 'for', 'nlp', '.', 'it', 'can', 'token', 'sentenc', 'and', 'word', '.', 'it', 'includ', 'variou', 'nlp', 'librari', 'for', 'text', 'analysi', '.']\n",
      "\n",
      "Lemmatized Word: ['NLTK', 'is', 'a', 'powerful', 'tool', 'for', 'NLP', '.', 'it', 'can', 'tokenize', 'sentence', 'and', 'word', '.', 'It', 'include', 'various', 'NLP', 'library', 'for', 'text', 'analysis', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "print()\n",
    "print(\"Lemmatized Word:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8128dba-6557-4148-9d8a-5df665ab7599",
   "metadata": {},
   "source": [
    "# Stop Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20d10b9d-ca44-4e65-b39c-0e026d3a8c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f895699-2ff0-4d9e-83ce-abeb10133a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Word: ['NLTK', 'powerful', 'tool', 'NLP', '.', 'tokenize', 'sentences', 'word', '.', 'include', 'various', 'NLP', 'libraries', 'text', 'analysis', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "print(\"Filtered Word:\", filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2ae9f-ec04-4932-a3e6-3d7983ed5b13",
   "metadata": {},
   "source": [
    "# Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1edcf3df-30a6-4920-9ef5-ecb9803bb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Distribution: <FreqDist with 20 samples and 24 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "freq_dist = FreqDist(words)\n",
    "print(\"Frequency Distribution:\", freq_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff7273-9f62-45d5-91a7-258ee6da5d71",
   "metadata": {},
   "source": [
    "# Concordance and Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03adb1a8-4f76-4cda-b871-0b848e967602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 1 of 1 matches:\n",
      " NLTK is a powerful tool for NLP . it can \n",
      "\n",
      "Concordance Result: None\n",
      "\n",
      "Similar Words: None\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "\n",
    "text_object = Text(words)\n",
    "concordance_result = text_object.concordance('NLTK')\n",
    "similar_words = text_object.similar('tool')\n",
    "print(\"Concordance Result:\", concordance_result)\n",
    "print()\n",
    "print(\"Similar Words:\", similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21160d03-8687-4ff1-a5c4-d935c0384215",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8deac954-a2c4-4fbe-8470-5bf17cc2e793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4140c6bc-9cec-42eb-8024-648b4c585993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Score: {'neg': 0.0, 'neu': 0.818, 'pos': 0.182, 'compound': 0.4588}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment_score = sia.polarity_scores(text)\n",
    "print(\"Sentiment Analysis Score:\", sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4fd52-8e21-4fa2-9904-b1a9e611bf9e",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7755ee38-196e-4c4d-bd48-7680968c56f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Result: (S\n",
      "  (ORGANIZATION NLTK/NNP)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  powerful/JJ\n",
      "  tool/NN\n",
      "  for/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  ./.\n",
      "  it/PRP\n",
      "  can/MD\n",
      "  tokenize/VB\n",
      "  sentences/NNS\n",
      "  and/CC\n",
      "  word/NN\n",
      "  ./.\n",
      "  It/PRP\n",
      "  include/VBP\n",
      "  various/JJ\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  libraries/NNS\n",
      "  for/IN\n",
      "  text/JJ\n",
      "  analysis/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "pos_tags_for_ner = pos_tag(tokens)\n",
    "ner_result = ne_chunk(pos_tags_for_ner)\n",
    "print(\"NER Result:\", ner_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f187577-6a4a-4036-afd1-e5320e2f0dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b123f-9952-448b-bce5-eb76debf7c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
